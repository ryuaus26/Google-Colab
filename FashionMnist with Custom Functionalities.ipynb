{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMbmhPH/IUEyhJBiHDyEq5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryuaus26/Google-Colab/blob/main/FashionMnist%20with%20Custom%20Functionalities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_5ojuzVPdLD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import keras\n",
        "import matplotlib.pyplot\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.core.dense import Dense\n",
        "class CustomDenseLayer(keras.layers.Layer):\n",
        "  def __init__(self,units,activation= None):\n",
        "    super().__init__()\n",
        "    self.units = units\n",
        "    self.activation = activation\n",
        "\n",
        "  def build(self,input_shape):\n",
        "    w_init = tf.random_normal_initializer()\n",
        "    self.w = tf.Variable(initial_value=w_init(shape=(input_shape[-1],self.units),dtype='float32'),trainable=True)\n",
        "    b_init = tf.zeros_initializer()\n",
        "    self.b = tf.Variable(initial_value=b_init(shape=(self.units,),dtype='float32'),trainable=True)\n",
        "\n",
        "  def call(self,inputs):\n",
        "    if self.activation == tf.nn.softmax or self.activation==\"softmax\":\n",
        "      output = tf.nn.softmax(tf.matmul(inputs, self.w) + self.b,axis=-1)\n",
        "    elif self.activation is not None:\n",
        "      output = tf.matmul(inputs, self.w) + self.b\n",
        "    else:\n",
        "      output = self.activation(tf.matmul(inputs, self.w) + self.b)\n",
        "    return output\n",
        "\n",
        "\n",
        "def base_model():\n",
        "  inputs = keras.layers.Input(shape=(784,))\n",
        "  x = CustomDenseLayer(units=64,activation='relu')(inputs)\n",
        "  x = CustomDenseLayer(units=64,activation='relu')(x)\n",
        "  outputs = CustomDenseLayer(units=10,activation='softmax')(x)\n",
        "  model= keras.Model(inputs=inputs,outputs=outputs)\n",
        "  return model\n",
        "\n",
        "train_data = tfds.load('fashion_mnist',split='train')\n",
        "test_data = tfds.load('fashion_mnist',split='test')\n",
        "\n",
        "def format_image(data):\n",
        "  image = data['image']\n",
        "  # Flattened to a 1D vector of length 784\n",
        "  image = tf.reshape(image,[-1])\n",
        "  image = tf.cast(image,tf.float32)\n",
        "  image = image/255.0\n",
        "  return image, data['label']\n",
        "\n",
        "# the keyword map() applies the function format_image across all the images stored in train_data and test_data variables\n",
        "train_data = train_data.map(format_image)\n",
        "test_data = test_data.map(format_image)\n",
        "\n",
        "#Allows for faster data\n",
        "batch_size = 64\n",
        "train = train_data.shuffle(buffer_size=1024).batch(batch_size)\n",
        "test = test_data.batch(batch_size=batch_size)"
      ],
      "metadata": {
        "id": "N2N44iXXP3xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.Adam()\n",
        "train_metrics = tf.metrics.CategoricalAccuracy()\n",
        "val_metrics = tf.metrics.CategoricalAccuracy()\n"
      ],
      "metadata": {
        "id": "xYIJZeo9SvB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = base_model()\n",
        "plot_model(model, to_file='custom_model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "def apply_gradient(model,x,y,optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(x)\n",
        "    loss_value = loss_object(y_true=y,y_pred=logits)\n",
        "\n",
        "  gradients = tape.gradient(loss_value,model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(gradients,model.trainable_weights))\n",
        "\n",
        "\n",
        "  return logits,loss_value\n",
        "\n",
        "\n",
        "def train_one_epoch():\n",
        "  pbar = tqdm(total=len(list(enumerate(train))), position=0, leave=True, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} ')\n",
        "  losses = []\n",
        "  for step, (x_train_batch,y_train_batch) in enumerate(train):\n",
        "    logits,loss_value = apply_gradient(model,x_train_batch,y_train_batch,optimizer)\n",
        "    train_metrics.update_state(y_train_batch,logits)\n",
        "    losses.append(loss_value)\n",
        "    pbar.set_description(f\"Training loss for step {step} {loss_value}\")\n",
        "    pbar.update()\n",
        "  return losses\n",
        "\n",
        "def perform_validation():\n",
        "  losses = []\n",
        "  for (x_val,y_val) in test:\n",
        "    logits = model(x_val)\n",
        "    val_loss = loss_object(logits,y_val)\n",
        "    val_metrics.update_state(y_val,logits)\n",
        "    losses.append(val_loss)\n",
        "  return losses\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ItGRTa_AZNOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e272721-4152-4cfa-dd7d-0b0a6fd166a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_44 (InputLayer)       [(None, 784)]             0         \n",
            "                                                                 \n",
            " custom_dense_layer_104 (Cus  (None, 64)               50240     \n",
            " tomDenseLayer)                                                  \n",
            "                                                                 \n",
            " custom_dense_layer_105 (Cus  (None, 64)               4160      \n",
            " tomDenseLayer)                                                  \n",
            "                                                                 \n",
            " custom_dense_layer_106 (Cus  (None, 10)               650       \n",
            " tomDenseLayer)                                                  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Start training\n",
        "\n",
        "EPOCHS = 20\n",
        "epoch_val_losses, epoch_train_losses = [], []\n",
        "\n",
        "for epoch in (range(EPOCHS)):\n",
        "  print(\"Start of epoch :{}\".format(epoch))\n",
        "\n",
        "  losses_train = train_one_epoch()\n",
        "  train_acc = train_metrics.result()\n",
        "\n",
        "  losses_val = perform_validation()\n",
        "  val_acc = val_metrics.result()\n",
        "\n",
        "  losses_train_mean = np.mean(losses_train)\n",
        "  epoch_train_losses.append(losses_train_mean)\n",
        "  losses_val_mean = np.mean(losses_val)\n",
        "  epoch_val_losses.append(losses_val_mean)\n",
        "  print(\"Epoch: {} Train Loss: {}  Val Loss: {}  Train Accuracy: {} Val Accuracy {} \".format(epoch,losses_train,losses_val,train_acc,val_acc))\n",
        "  train_acc.reset()\n",
        "  val_acc.reset()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmFhHlBib31m",
        "outputId": "ee225324-4094-491b-d1d9-211ed6002fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of epoch :0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training loss for step 230 0.530408501625061:  25%|██▍       | 231/938 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "guq3C-VXfZJm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}